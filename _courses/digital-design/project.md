---
title: "课程大作业：矩阵乘法加速器"
layout: course
collection: courses
parent: digital-sys
position: 1
permalink: /courses/digital-sys/project/
---

我们都知道神经网络依赖大量的矩阵运算，然而使用软件计算大矩阵乘法太慢了，即使是有并行度很高的GPU支持，计算用时仍有待优化。谷歌基于脉动阵列的想法，推出了TPU(Tensor Process Unit),实现了高能效比，高计算效率的双赢(当然也牺牲了通用性)。所以在这个大作业中，我们来实现一个大矩阵乘法模块(需要你从零写起，包括测试框架，综合脚本)。

你的模块将从SRAM中读入两个 $512 \times 512$，每个元素是$SINT8$的矩阵，将计算结果写回到一个SRAM中，并将这个模块使用开源综合工具yosys和45nm工艺库，进行带工艺库的综合。具体得分由以下因素确定：计算时间，计算精度，综合后的面积、功耗。具体要求见：[大作业说明](https://bonany.cc/digital_logic_lab/lab8.html)

笔者注：实际上这个评分标准十分迷惑，本来我们要写的是矩阵乘法加速器，结果老师把今年评分标准改成了面积优先(他直接给面积上加了个平方),这就导致笔者仔细写出来的$16 \times 16$脉动阵列的面积太大了，得分远不如只有一个乘加单元的方案，矩阵乘法“加速器”的得分甚至不如矩阵乘法“减速器”的得分！

以下是大作业的实现

---

可选的设计方案有：脉动阵列，流水线化，bit-serial乘法，ping-pong cache 

脉动阵列是一定要用的，其他优化方法则不一定。所以第一步，先来做一个$ 4 \times 4$的脉动阵列。脉动阵列的连接很简单，关键是怎么把数据按照顺序送入阵列。为此，我们构建两个数据控制模块，假设一次读入矩阵的一行(一列)，通过这个控制模块把数据延时后输入阵列。

延时的原则是: 元素$ A_{ij，0 \le i < n,0 \le j < n}$延时$ i + j $个周期输出。





---