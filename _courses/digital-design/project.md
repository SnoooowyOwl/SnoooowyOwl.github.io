---
title: "课程大作业：矩阵乘法加速器"
layout: course
collection: courses
parent: digital-sys
position: 1
permalink: /courses/digital-sys/project/
---

我们都知道神经网络依赖大量的矩阵运算，然而使用软件计算呢大矩阵乘法太慢了，即使是有并行度很高的GPU支持，计算用时 仍有待优化。谷歌基于脉动阵列的想法，推出了TPU(Tensor Process Unit),实现了高能效比，高计算效率的目标(当然也牺牲了通用性)。所以在这个大作业中，我们来实现一个大矩阵乘法模块(需要你从零写起，包括测试框架，综合脚本)。

你的模块将从SRAM中读入两个$512 \times 512$，每个元素是$SINT8$的矩阵，并将计算结果写回到一个SRAM中，并将这个模块使用开源综合工具yosys和45nm工艺库，进行带工艺库的综合。具体得分由以下因素确定：计算时间，计算精度，综合后的面积、功耗。具体要求见：[大作业说明](https://bonany.cc/digital_logic_lab/lab8.html)

笔者注：实际上这个评分标准十分迷惑，本来我们要写的是矩阵乘法加速器，结果老师把今年评分标准改成了面积有限(他直接给面积上加了个平方),这就导致笔者仔细写出来的$16 \times 16$脉动阵列的得分远不如只写了一个乘加单元。笔者还是太先入为主了，矩阵乘法“加速器”的得分甚至不如矩阵乘法"减速器“的得分高。

---